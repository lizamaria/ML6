{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "decent-endorsement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from __future__ import print_function\n",
    "import fitz\n",
    "import sys\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spiritual-scratch",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare the path of your file\n",
    "file_path = \"1.pdf\"  #/pdf_file/data.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "crazy-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = fitz.open(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hearing-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_font_style_counts(doc, granularity=False):\n",
    "    \"\"\"Extracts fonts and their usage in PDF documents.\n",
    "    :param doc: PDF document to iterate through\n",
    "    :type doc: <class 'fitz.fitz.Document'>\n",
    "    :param granularity: also use 'font', 'flags' and 'color' to discriminate text\n",
    "    :type granularity: bool\n",
    "    :rtype: [(font_size, count), (font_size, count}], dict\n",
    "    :return: most used fonts sorted by count, font style information\n",
    "    \"\"\"\n",
    "    styles = {}\n",
    "    font_counts = {}\n",
    "\n",
    "    for page in doc:\n",
    "        blocks = page.getText(\"dict\")[\"blocks\"]\n",
    "        for b in blocks:  # iterate through the text blocks\n",
    "            if b['type'] == 0:  # block contains text\n",
    "                for l in b[\"lines\"]:  # iterate through the text lines                    \n",
    "                    for s in l[\"spans\"]:  # iterate through the text spans                    \n",
    "                        if granularity:\n",
    "                            identifier = (int(s['text'].isupper()), int('bold' in s['font'].lower()), float(s['size'])) #\"{0}_{1}_{2}_{3}\".format(s['size'], s['flags'], s['font'], s['color'])\n",
    "                            styles[identifier] = {'size': s['size'], 'flags': s['flags'], 'font': s['font'],\n",
    "                                                  'color': s['color']}\n",
    "                        else:\n",
    "                            identifier = \"{0}\".format(s['size'])\n",
    "                            styles[identifier] = {'size': s['size'], 'font': s['font']}\n",
    "\n",
    "                        font_counts[identifier] = font_counts.get(identifier, 0) + 1  # count the fonts usage\n",
    "    font_counts = sorted(font_counts.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "    if len(font_counts) < 1:\n",
    "        raise ValueError(\"Zero discriminating fonts found!\")\n",
    "    \n",
    "    return font_counts, styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "compact-smell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_font_tags(font_counts, styles):\n",
    "    \"\"\"Returns dictionary with font sizes as keys and tags as value.\n",
    "    :param font_counts: (font_size, count) for all fonts occuring in document\n",
    "    :type font_counts: list\n",
    "    :param styles: all styles found in the document\n",
    "    :type styles: dict\n",
    "    :rtype: dict\n",
    "    :return: all element tags based on font-sizes\n",
    "    \"\"\"\n",
    "    p_style = font_counts[0][0] # get style for most used font by count (paragraph)\n",
    "\n",
    "    # sorting the font sizes high to low, so that we can append the right integer to each tag \n",
    "    font_styles = []\n",
    "    for ((upper, bold, font_size), count) in font_counts:\n",
    "        font_styles.append((upper, bold, font_size))\n",
    "    font_styles.sort(key=itemgetter(0,2,1), reverse=True)\n",
    "#     return font_styles\n",
    "\n",
    "    # aggregating the tags for each font size\n",
    "    idx = 0\n",
    "    style_tag = {}\n",
    "    for style in font_styles:\n",
    "        idx += 1\n",
    "        if style == p_style:\n",
    "            idx = 0\n",
    "            style_tag[style] = '<p>'\n",
    "            continue\n",
    "        if style[2] > p_style[2]:\n",
    "            style_tag[style] = '<h{0}>'.format(idx)\n",
    "        elif style[2] < p_style[2]:\n",
    "            style_tag[style] = '<s{0}>'.format(idx)\n",
    "        else:\n",
    "            style_tag[style] = '<h{0}>'.format(idx)    \n",
    "    return style_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "early-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_tags_to_content(doc, style_tag):\n",
    "    \"\"\"Scrapes headers & paragraphs from PDF and return texts with element tags.\n",
    "    :param doc: PDF document to iterate through\n",
    "    :type doc: <class 'fitz.fitz.Document'>\n",
    "    :param style_tag: textual element tags for each style (uppercase_flag, bold_flag, size)\n",
    "    :type style_tag: dict\n",
    "    :rtype: list\n",
    "    :return: texts with pre-prended element tags\n",
    "    \"\"\"\n",
    "    header_para = []  # list with headers and paragraphs\n",
    "    first = True  # boolean operator for first header\n",
    "    previous_s = {}  # previous span\n",
    "\n",
    "    for page in doc:\n",
    "        blocks = page.getText(\"dict\")[\"blocks\"]\n",
    "        i=0\n",
    "        for b in blocks:  # iterate through the text blocks\n",
    "#             i+=1\n",
    "#             if i == 4:\n",
    "#                 break\n",
    "#             print(i)\n",
    "#             pp.pprint(b)\n",
    "\n",
    "            if b['type'] == 0:  # this block contains text\n",
    "\n",
    "                # REMEMBER: multiple fonts and sizes are possible IN one block\n",
    "\n",
    "                block_string = \"\"  # text found in block\n",
    "                for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                    for s in l[\"spans\"]:  # iterate through the text spans\n",
    "                        if s['text'].strip():  # removing whitespaces:\n",
    "                            if first:\n",
    "                                previous_s = s\n",
    "                                first = False\n",
    "                                s_key = (int(s['text'].isupper()), int('bold' in s['font'].lower()), float(s['size']))\n",
    "                                block_string = style_tag[s_key] + s['text']\n",
    "                            else:\n",
    "                                s_key = (int(s['text'].isupper()), int('bold' in s['font'].lower()), float(s['size']))\n",
    "                                previous_key = (int(previous_s['text'].isupper()), int('bold' in previous_s['font'].lower()), float(previous_s['size']))\n",
    "                                if s_key == previous_key:\n",
    "\n",
    "                                    if block_string and all((c == \"|\") for c in block_string):\n",
    "                                        # block_string only contains pipes\n",
    "                                        block_string = style_tag[s_key] + s['text']\n",
    "                                    if block_string == \"\":\n",
    "                                        # new block has started, so append size tag\n",
    "                                        block_string = style_tag[s_key] + s['text']\n",
    "                                    else:  # in the same block, so concatenate strings\n",
    "                                        block_string += \" \" + s['text']\n",
    "\n",
    "                                else:\n",
    "                                    if block_string:\n",
    "                                        header_para.append(block_string.replace('|','').strip(\".:: ·\"))\n",
    "                                    block_string = style_tag[s_key] + s['text']\n",
    "\n",
    "                                previous_s = s\n",
    "\n",
    "                    # new block started, indicating with a pipe\n",
    "                    block_string += \"|\"\n",
    "\n",
    "                if block_string:\n",
    "                    header_para.append(block_string.replace('|','').strip(\".:: ·\"))\n",
    "    return header_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "recognized-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "font_counts, styles = get_font_style_counts(doc, granularity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "egyptian-march",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 0, 32.77130126953125): '<h1>',\n",
       " (1, 1, 10.020000457763672): '<h2>',\n",
       " (1, 0, 10.020000457763672): '<h3>',\n",
       " (1, 0, 7.019999980926514): '<s4>',\n",
       " (1, 0, 6.0): '<s5>',\n",
       " (0, 0, 32.77130126953125): '<h6>',\n",
       " (0, 0, 15.0): '<h7>',\n",
       " (0, 1, 13.979999542236328): '<h8>',\n",
       " (0, 1, 12.0): '<h9>',\n",
       " (0, 0, 12.0): '<h10>',\n",
       " (0, 1, 10.020000457763672): '<h11>',\n",
       " (0, 0, 10.020000457763672): '<p>',\n",
       " (0, 0, 9.0): '<s1>',\n",
       " (0, 0, 8.991100311279297): '<s2>',\n",
       " (0, 0, 7.980000019073486): '<s3>',\n",
       " (0, 0, 7.019999980926514): '<s4>',\n",
       " (0, 0, 1.0199999809265137): '<s5>'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_tag = get_font_tags(font_counts, styles)\n",
    "style_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "criminal-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_text = assign_tags_to_content(doc, style_tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "saving-wealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#keywords per section title\n",
    "section_titles={\n",
    "    1:['1','identification'],\n",
    "    2:['2','hazard','identification'],\n",
    "    3:['3','composition','ingredients'],\n",
    "    4:['4','first','aid','measures'],\n",
    "    5:['5','fire','fight','measures'],\n",
    "    6:['6','accidental','release','measures'],\n",
    "    7:['7','handling','storage'],\n",
    "    8:['8','exposure','controls','personal','protection'],\n",
    "    9:['9','physical','chemical','properties'],\n",
    "    10:['10','stability','reactivity'],\n",
    "    11:['11','information'],\n",
    "    12:['12','ecological','information'],\n",
    "    13:['13','disposal','considerations'],\n",
    "    14:['14','transport','information'],\n",
    "    15:['15','regulatory','information'],\n",
    "    16:['16','other','information'],\n",
    "}\n",
    "\n",
    "def convert_tagged_text_into_map(text):        \n",
    "    header_map={}\n",
    "    for line in text:\n",
    "        header=extract_header(line)\n",
    "        if header!=None:\n",
    "            if header_map.get(header)==None:\n",
    "                header_map[header]=[line.lower()]\n",
    "            else:\n",
    "                header_map[header].append(line.lower())\n",
    "    return header_map\n",
    "\n",
    "def find_section_header(header_dict):\n",
    "    for key in header_map.keys():\n",
    "        if check_section_titles_present(header_dict[key])==True:\n",
    "            return key\n",
    "    return None\n",
    "\n",
    "#turns a list into a regexp, use headervalue to pass a specific header\n",
    "def sectiontitle_regexp(values,headervalue=\"<hx>\"):\n",
    "    if headervalue==\"<hx>\":\n",
    "        regexp=\"<h\\d+>.*\"\n",
    "    else:\n",
    "        regexp=headervalue+\".*\"\n",
    "    for i in values:\n",
    "        regexp=regexp+i+\".*\"    \n",
    "    return regexp\n",
    "\n",
    "#extracts '<hx>'\n",
    "def extract_header(line,only_h=True):\n",
    "    if only_h==True:\n",
    "        regexp=\"<h\\d+>\"\n",
    "        x=re.search(regexp, line)\n",
    "        if x!=None:\n",
    "            return x.group()\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        regexp=\"<.+>\"\n",
    "        x=re.search(regexp, line)\n",
    "        if x!=None:\n",
    "            return x.group()\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "#checks if all 16 section_titles are present in the list\n",
    "def check_section_titles_present(values):\n",
    "    counter=1    \n",
    "    while counter<17:\n",
    "        r = re.compile(sectiontitle_regexp(section_titles[counter]))\n",
    "        newlist = list(filter(r.match, values))\n",
    "        if len(newlist)==0:\n",
    "            return False\n",
    "        counter=counter+1        \n",
    "    return True\n",
    "    \n",
    "header_map=convert_tagged_text_into_map(tagged_text)\n",
    "section_title_header=find_section_header(header_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "theoretical-facial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<h9>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_title_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "distant-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_into_dict(tagged_text,section_title_header):\n",
    "    counter=1\n",
    "    next_child_regexp=sectiontitle_regexp(section_titles[counter],section_title_header)\n",
    "    current_child=\"Header\"\n",
    "    temp_dict={\"Header\":[]}\n",
    "    for line in tagged_text:\n",
    "        #start of file and no child yet found\n",
    "        x=re.search(next_child_regexp, line.lower())\n",
    "        #found a child\n",
    "        if x!=None:\n",
    "            current_child=line\n",
    "            temp_dict[current_child]=[]\n",
    "            if counter<16:\n",
    "                counter=counter+1\n",
    "                next_child_regexp=sectiontitle_regexp(section_titles[counter],section_title_header)                \n",
    "        else:\n",
    "#             cleaned_line = re.sub(r'<[h|s]\\d+>|<p>', '', line)\n",
    "#             if cleaned_line:\n",
    "#                 temp_dict[current_child].append(cleaned_line)\n",
    "            temp_dict[current_child].append(line)        \n",
    "    return temp_dict\n",
    "\n",
    "def extract_headers_from_list(values):\n",
    "    headers=[]\n",
    "    for i in values:\n",
    "        if i!=None:\n",
    "            headers.append(extract_header(i,False))\n",
    "    return list(set(headers))\n",
    "\n",
    "\n",
    "def get_next_smaller_header(base_header,values):\n",
    "    all_headers=extract_headers_from_list(values)\n",
    "    #remove None values\n",
    "    base_header=base_header.replace('<h','')\n",
    "    base_header=int(base_header.replace('>',''))\n",
    "    filtered=list(filter(None.__ne__, values))\n",
    "    header_filtered=list(filter(lambda x : 'h' in x, filtered))\n",
    "    debracketed_list=[]\n",
    "    for item in header_filtered:\n",
    "        debracketed=item.replace('<h','')\n",
    "        debracketed=debracketed.replace('>','')\n",
    "        debracketed=int(debracketed)\n",
    "        debracketed_list.append(debracketed)\n",
    "    smaller_headings=list(filter(lambda x : x > base_header,debracketed_list))    \n",
    "    if len(smaller_headings)==0:\n",
    "        return '<hx>'\n",
    "    else:\n",
    "        smaller_headings.sort()\n",
    "        return '<h'+str(smaller_headings[-1])+'>'\n",
    "    \n",
    "#returns list[pairs] met de pairs(startidx,laatsteregel voor volgende) \n",
    "def record_span(values,header):\n",
    "    counter=0\n",
    "    children=[]\n",
    "    for line in values:\n",
    "        if header in line:\n",
    "            children.append(counter)\n",
    "        counter=counter+1\n",
    "    return children\n",
    "\n",
    "def convert_children_into_parents(values,parent_locations):\n",
    "    counter=0\n",
    "    temp_list=[]\n",
    "    while counter < parent_locations[0]:\n",
    "        temp_list.append(values[counter])\n",
    "        counter=counter+1\n",
    "    parent_counter=0\n",
    "    current_parent_idx=parent_locations[0]    \n",
    "    while parent_counter<len(parent_locations)-1:\n",
    "        \n",
    "        next_parent_idx=parent_locations[parent_counter+1]    \n",
    "        temp_list.append({values[current_parent_idx]:values[current_parent_idx+1:next_parent_idx]})\n",
    "        current_parent_idx=next_parent_idx\n",
    "        parent_counter=parent_counter+1\n",
    "    temp_list.append({values[current_parent_idx]:values[current_parent_idx+1:]})\n",
    "    return temp_list\n",
    "        \n",
    "def scourge(end_dict):\n",
    "    temp_dict={}\n",
    "    \n",
    "    key=list(end_dict.keys())[0]\n",
    "    header=extract_header(key,only_h=True)\n",
    "    if header==None:\n",
    "        return end_dict\n",
    "        print(\"Got passed something is a dict ,but doesnt have a header?\",key)\n",
    "        raise Exception\n",
    "    else:\n",
    "        child_header=get_next_smaller_header(header,extract_headers_from_list(end_dict[key]))\n",
    "        if child_header=='<hx>':\n",
    "            #no possible subdivisions, return original dict\n",
    "            return end_dict\n",
    "        else:\n",
    "            #subdivisions possible\n",
    "            parent_corpus=end_dict[key]\n",
    "            next_gen_parents=record_span(parent_corpus,child_header)\n",
    "            if len(next_gen_parents)>0:\n",
    "                temp_dict[key]=convert_children_into_parents(parent_corpus,next_gen_parents)\n",
    "                temp_list=[]\n",
    "                for val in temp_dict[key]:\n",
    "                    if isinstance(val,dict):\n",
    "                        temp_list.append(scourge(val))\n",
    "                    else:\n",
    "#                         print(f\"type({val}): {type(val)}\")\n",
    "#                         cleaned_val = re.sub(r'<[h|s]\\d+>|<p>', '', val)\n",
    "#                         temp_list.append(cleaned_val)\n",
    "                        temp_list.append(val)\n",
    "                temp_dict[key]=temp_list\n",
    "            return temp_dict\n",
    "    \n",
    "def clean_dictionary(curr_dict):\n",
    "    clean_dict = {}\n",
    "    for key, val in curr_dict.items():\n",
    "        new_key = re.sub(r'<[h|s]\\d+>|<p>', '', key)\n",
    "        new_val = []\n",
    "        for v in val:\n",
    "            if isinstance(v, dict):\n",
    "                new_val.append(clean_dictionary(v))\n",
    "            else:\n",
    "                clean_v = re.sub(r'<[h|s]\\d+>|<p>|\\*', '', v).strip()\n",
    "                if clean_v:\n",
    "                    new_val.append(clean_v)\n",
    "        clean_dict[new_key] = new_val\n",
    "    return clean_dict    \n",
    "\n",
    "temp_dict=convert_text_into_dict(tagged_text,find_section_header(header_map))\n",
    "temp_list=[]\n",
    "for k,v in temp_dict.items():\n",
    "    temp_list.append(clean_dictionary(scourge({k:v})))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "guided-verification",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(temp_list, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
